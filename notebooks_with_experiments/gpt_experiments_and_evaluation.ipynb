{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0v56WPbT8_Q"
      },
      "source": [
        "# Comparison of results between GPT-3.5-turbo, GPT-4o-mini and human annotator\n",
        "In the following notebook there are compared various possible methods which are either used or could be used by the company. Currently the company is using GPT-3.5-turbo model to annotate the category of the given text. Nowadays, better models are available. What is more, more cleaning of the data can be implemented, to increase the performance of used models.\n",
        "\n",
        "Here:\n",
        "* each experiment consists of input data, for which predictions by GPT-3.5-turbo and GPT-4o-mini are made, each 3 times,\n",
        "* the predictions are made separately for each of the types of the tasks: 1) category classification, 2) sentiment and 3) recognizing companies.\n",
        "* each prediction is compared with human annotated labels. The final score of each model is an average of scores for each of the tasks separately.\n",
        "* there are four types of input data: 1) not preprocessed, 2) preprocessed by GPT-4o-mini model, 3) preprocessed using regex definded by human annotator based on randomly chosen samples, 4) preprocessed by human annotator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1xlb4VSNozP"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r42sn7jBxvM_"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from config_experiments import (\n",
        "    OPEN_AI_KEY,\n",
        "    PATH_TO_SAVE_RESULTS\n",
        ")\n",
        "\n",
        "from utils import (\n",
        "    load_data_preprocessed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "maBnUxzqxMYc"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=OPEN_AI_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_gt=load_data_preprocessed('gt')\n",
        "not_preprocessed_data = load_data_preprocessed('not_preprocessed_data')\n",
        "processed_4o_data = load_data_preprocessed('processed_4o_data')\n",
        "processed_regex_data = load_data_preprocessed('processed_regex_data')\n",
        "processed_human_data = load_data_preprocessed('processed_human_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "Aeml9GPX2Vs5",
        "outputId": "d1afb336-4a53-4d10-a7f4-dfc03520fa7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"The BBC's director-general has tried to calm tensions among staff over the Israel-Gaza war, telling them to think 'carefully about the language that you use' in the workplace. Tim Davie said employees needed to be 'kind' to each other and 'no one should ever face any fear or prejudice' at their place of work. His email to his workforce comes as one insider at the corporation reported there had been arguments between staff with different views on the Middle-East crisis. There have already been reports of how Jewish staff had been upset at the corporation's refusal to describe Hamas fighters as terrorists. But it has also been claimed that some of its own journalists believe the BBC has been too soft on Israel and was 'dehumanising' Palestinian civilians. Yesterday in an apparent recognition of the tensions among staff, Mr Davie called for calm and respect in the workplace over the issue. Mr Davie has called for calm and respect in the workplace over the issue A mother covers her child's face to protect from the smoke as Palestinians leave from the northern part of the Gaza to flee the central and southern parts of the Gaza Strip Admitting it had been a 'incredibly demanding' and 'stressful' time in recent weeks, he wrote: ' Our duty of care to all those impacted is paramount and I would ask everyone to be kind, considerate and supportive of each other. 'It is essential that we act with generosity and humanity, creating an environment where we look after each other in these troubled times, particularly those people most impacted by these awful events.' He added: 'No one should ever face any fear or prejudice in a workplace, and it requires all of us to pull together as one team to live our values. 'This can be harder in these polarised times but we should set the standard as an inclusive, safe environment. I would ask every one of you personally to contribute to this. 'This includes thinking carefully about the language that you use, in person, on email, and also on social media.' Mr Davie went on to provide details for staff who needed support as well as telling them they could use the corporation's whistleblowing services. A BBC source said: 'The BBC isn't some sort of monolithic organisation that doesn't have human beings. One BBC insider admitted they were aware of heated arguments taking place between staff about the war 'There are people working in all sorts of parts of the world and people who like everyone else feels the stresses and strains in relation to covering a complex and difficult conflict.' One BBC insider admitted they were aware of heated arguments taking place between staff about the war. Jewish staff already annoyed about the corporation's refusal to call Hamas fighters terrorists, were further upset when a John Simpson blog about this editorial decision referred to the Nazis. A recent report by The Times said staff who felt the corporation had been too soft on Israel and was 'dehumanising' Palestinian civilians, had been left crying in the toilets, while freelancers had not turned up to work because of it. This comes as the corporation has been fiercely criticised for its coverage during the crisis. Senior figures in the Jewish community in the UK, including the Chief Rabbi, Ephraim Mirvis have criticised the decision not to call Hamas terrorists. The president of Israel Isaac Herzog even attacked the BBC over this decision. The BBC also admitted that a controversial TV report about the cause of a Gaza hospital explosion had been flawed. In his staff email, Mr Davie paid tribute to its news teams saying 'those on the ground' had faced 'significant pressures' in doing their work.\\n\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "not_preprocessed_data[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "-2wft7TqiN2Y"
      },
      "outputs": [],
      "source": [
        "def ask_model(data, which_task = \"category\", which_model=\"gpt-3.5-turbo\"):\n",
        "  answers=[\"\" for _ in range(len(data))]\n",
        "  answers_confidence=[\"\" for _ in range(len(data))]\n",
        "  for i in range(len(data)):\n",
        "    if which_task==\"category\":\n",
        "      prompt=f\"\"\"You are a text classification endpoint, classifying given text into categories:\n",
        "      human_employee_rights\n",
        "      diversity_equity_inclusion\n",
        "      environment\n",
        "      animal_care\n",
        "      corporate_transparency\n",
        "      business_involvement\n",
        "      political_and_religious_views\n",
        "\n",
        "      If you are not sure, return other.\n",
        "      Return only name of the category.\n",
        "\n",
        "      Texts to classify:\n",
        "\n",
        "      {data[i]}\n",
        "      \"\"\"\n",
        "    elif which_task==\"sentiment\":\n",
        "      prompt=f\"\"\"You are a sentiment classification endpoint, classifying given text into: positive, neutral, negative.\n",
        "      Return only the sentiment: 'positive', 'neutral', 'negative'.\n",
        "      Texts to classify:\n",
        "\n",
        "      {data[i]}\n",
        "      \"\"\"\n",
        "    elif which_task==\"company\":\n",
        "      prompt=f\"\"\"You are a NER endpoint, finding names of the companies occuring in the article.\n",
        "      Return only those names. If there are more than one companies, separate each name with ','.\n",
        "      If there will be no company in the article, return 'no company'.\n",
        "\n",
        "      Text:\n",
        "\n",
        "      {data[i]}\n",
        "      \"\"\"\n",
        "    else:\n",
        "      return answers, answers_confidence\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "      model=which_model,\n",
        "      seed=123,\n",
        "      messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ],\n",
        "      logprobs=True,\n",
        "      top_logprobs=5,\n",
        "      temperature=0\n",
        "    )\n",
        "\n",
        "    answers[i] = completion.choices[0].message.content\n",
        "    power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "    answers_confidence[i] = np.round(np.exp(power)*100, 1)\n",
        "\n",
        "  return answers, answers_confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-zTfxfg-Gma6"
      },
      "outputs": [],
      "source": [
        "def conduct_experiments(input_data, type_of_data=\"notpreprocessed\", which_model=\"gpt-3.5-turbo\", exp_number=1):\n",
        "  category_not_preprocessed=[[\"\" for _ in range(len(input_data))] for _ in range(3)]\n",
        "  category_not_preprocessed_confidence=[[\"\" for _ in range(len(input_data))] for _ in range(3)]\n",
        "  sentiment_not_preprocessed=[[\"\" for _ in range(len(input_data))] for _ in range(3)]\n",
        "  sentiment_not_preprocessed_confidence=[[\"\" for _ in range(len(input_data))] for _ in range(3)]\n",
        "  company_not_preprocessed=[[\"\" for _ in range(len(input_data))] for _ in range(3)]\n",
        "  company_not_preprocessed_confidence=[[\"\" for _ in range(len(input_data))] for _ in range(3)]\n",
        "  print(\"Lists created.\")\n",
        "\n",
        "  for i in range(3):\n",
        "    category_not_preprocessed[i], category_not_preprocessed_confidence[i]=ask_model(input_data, which_task = \"category\", which_model=which_model)\n",
        "    print(f\"{type_of_data} number {i} category done.\")\n",
        "    sentiment_not_preprocessed[i], sentiment_not_preprocessed_confidence[i]=ask_model(input_data, which_task = \"sentiment\", which_model=which_model)\n",
        "    print(f\"{type_of_data} number {i} sentiment done.\")\n",
        "    company_not_preprocessed[i], company_not_preprocessed_confidence[i]=ask_model(input_data, which_task = \"company\", which_model=which_model)\n",
        "    print(f\"{type_of_data} number {i} company done.\")\n",
        "  print(\"Asking model done.\")\n",
        "\n",
        "  #save to files\n",
        "  df_category_not_preprocessed=pd.DataFrame(category_not_preprocessed)\n",
        "  df_category_not_preprocessed.to_csv(f\"{PATH_TO_SAVE_RESULTS}experiment_{exp_number}/category_{type_of_data}.csv\", index=False, sep=';')\n",
        "  df_category_not_preprocessed_confidence=pd.DataFrame(category_not_preprocessed_confidence)\n",
        "  df_category_not_preprocessed_confidence.to_csv(f\"{PATH_TO_SAVE_RESULTS}experiment_{exp_number}/category_{type_of_data}_confidence.csv\", index=False, sep=';')\n",
        "\n",
        "  df_sentiment_not_preprocessed=pd.DataFrame(sentiment_not_preprocessed)\n",
        "  df_sentiment_not_preprocessed.to_csv(f\"{PATH_TO_SAVE_RESULTS}experiment_{exp_number}/sentiment_{type_of_data}.csv\", index=False, sep=';')\n",
        "  df_sentiment_not_preprocessed_confidence=pd.DataFrame(sentiment_not_preprocessed_confidence)\n",
        "  df_sentiment_not_preprocessed_confidence.to_csv(f\"{PATH_TO_SAVE_RESULTS}experiment_{exp_number}/sentiment_{type_of_data}_confidence.csv\", index=False, sep=';')\n",
        "\n",
        "  df_company_not_preprocessed=pd.DataFrame(company_not_preprocessed)\n",
        "  df_company_not_preprocessed.to_csv(f\"{PATH_TO_SAVE_RESULTS}experiment_{exp_number}/company_{type_of_data}.csv\", index=False, sep=';')\n",
        "  df_company_not_preprocessed_confidence=pd.DataFrame(company_not_preprocessed_confidence)\n",
        "  df_company_not_preprocessed_confidence.to_csv(f\"{PATH_TO_SAVE_RESULTS}experiment_{exp_number}/company_{type_of_data}_confidence.csv\", index=False, sep=';')\n",
        "\n",
        "  #calculate scores\n",
        "  score_category_not_preprocessed=0\n",
        "  score_sentiment_not_preprocessed=0\n",
        "  score_company_not_preprocessed=0\n",
        "\n",
        "  for i in range(3):\n",
        "    #lowercase all elements in all lists\n",
        "    category_not_preprocessed[i]=[x.lower() for x in category_not_preprocessed[i]]\n",
        "    sentiment_not_preprocessed[i]=[x.lower() for x in sentiment_not_preprocessed[i]]\n",
        "    score_category_not_preprocessed+=np.sum(category_not_preprocessed[i]==df_gt['Category'])\n",
        "    score_sentiment_not_preprocessed+=np.sum(sentiment_not_preprocessed[i]==df_gt['Sentiment'])\n",
        "    #for company the score will be to count the number of elements that are both in prediction and gt, divided by length of list in gt\n",
        "    for j in range(len(company_not_preprocessed)):\n",
        "      num_of_same_elements=len(set(company_not_preprocessed[i][j].split(\",\")) & set(df_gt['Company'][j].split(\",\")))\n",
        "      score_company_not_preprocessed += num_of_same_elements/len(df_gt['Company'][j].split(\",\"))\n",
        "\n",
        "  score_category_not_preprocessed /= 3\n",
        "  score_sentiment_not_preprocessed /= 3\n",
        "  score_company_not_preprocessed /= 3\n",
        "\n",
        "  print(f\"Score for {type_of_data} data for category for {which_model} is {score_category_not_preprocessed}.\")\n",
        "  print(f\"Score for {type_of_data} for sentiment for {which_model} is {score_sentiment_not_preprocessed}.\")\n",
        "  print(f\"Score for {type_of_data} for company for {which_model} is {score_company_not_preprocessed}.\")\n",
        "\n",
        "  f = open(f\"{PATH_TO_SAVE_RESULTS}experiment_{exp_number}/scores_{type_of_data}_model_{which_model}.txt\", \"a\")\n",
        "  f.write(f\"Category: {score_category_not_preprocessed}, sentiment: {score_sentiment_not_preprocessed}, company: {score_company_not_preprocessed}.\")\n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjNMyUcwPfZM"
      },
      "source": [
        "## Examples of prompts and results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For GPT-4o-mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "not_preprocessed_data=not_preprocessed_data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arYnFdo62_sE",
        "outputId": "e1c0fe49-e186-4fb9-ad01-c21b875e667d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "human_employee_rights 100.0 0.6447861194610596\n",
            "human_employee_rights 100.0 0.7493846416473389\n",
            "human_employee_rights 100.0 0.5567820072174072\n",
            "diversity_equity_inclusion 100.0 0.7454171180725098\n",
            "human_employee_rights 100.0 0.5667414665222168\n",
            "diversity_equity_inclusion 100.0 0.5902402400970459\n",
            "diversity_equity_inclusion 100.0 0.7475118637084961\n",
            "diversity_equity_inclusion 100.0 0.6907482147216797\n",
            "environment 100.0 0.4636249542236328\n",
            "environment 100.0 0.5377843379974365\n",
            "Average time: 0.6293020963668823\n"
          ]
        }
      ],
      "source": [
        "answers=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "answers_confidence=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sum_time=0\n",
        "for i in range(len(not_preprocessed_data)):\n",
        "  start_time=time.time()\n",
        "  article =f\"\"\"You are a text classification endpoint, classifying given text into categories:\n",
        "  human_employee_rights\n",
        "  diversity_equity_inclusion\n",
        "  environment\n",
        "  animal_care\n",
        "  corporate_transparency\n",
        "  business_involvement\n",
        "  political_and_religious_views\n",
        "\n",
        "  If you are not sure, return other.\n",
        "  Return only name of the category.\n",
        "\n",
        "  Texts to classify:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "  end_time=time.time()\n",
        "  answers[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  answers_confidence[i] = np.round(np.exp(power)*100, 1)\n",
        "  sum_time+=end_time-start_time\n",
        "  print(answers[i], answers_confidence[i], end_time-start_time)\n",
        "\n",
        "print(f\"Average time: {sum_time/len(not_preprocessed_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BHEUM485UAI",
        "outputId": "72cfdbb2-6177-4ceb-df95-7edeccc12d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative 73.1\n",
            "0.7310116291046143\n",
            "Amazon 100.0\n",
            "0.43302392959594727\n",
            "neutral 63.4\n",
            "0.6770398616790771\n",
            "Starbucks, Workers United, NBC Los Angeles, KUOW, The New York Times, The Philadelphia Inquirer, Placer.ai 100.0\n",
            "0.9027674198150635\n",
            "negative 90.2\n",
            "0.44138503074645996\n",
            "Amazon, Tripadvisor, Microsoft 99.6\n",
            "1.2336509227752686\n",
            "neutral 83.8\n",
            "0.9065001010894775\n",
            "BBC, Hamas, The Times, Israel 100.0\n",
            "0.8046102523803711\n",
            "negative 85.2\n",
            "0.8811581134796143\n",
            "Amazon 100.0\n",
            "0.6908962726593018\n",
            "negative 49.8\n",
            "0.7682647705078125\n",
            "BBC, GB News, LBC, Opera Holland Park, NCTJ, MailOnline 100.0\n",
            "0.7556369304656982\n",
            "negative 92.4\n",
            "0.7898740768432617\n",
            "BBC, Reform UK, Free Speech Union 100.0\n",
            "0.6687710285186768\n",
            "negative 56.6\n",
            "0.6208770275115967\n",
            "Aviva, BP, CBI, AXA, Zurich 100.0\n",
            "0.8453435897827148\n",
            "negative 86.7\n",
            "0.5124692916870117\n",
            "BP, British Museum, Greenpeace, National Portrait Gallery, Tate, Culture Unstained 98.6\n",
            "0.6523213386535645\n",
            "positive 99.3\n",
            "0.43262600898742676\n",
            "Carbonfuture, Microsoft, Exomad Green 100.0\n",
            "0.6782064437866211\n",
            "Average time sentiment: 0.6761205911636352\n",
            "Average time NER: 0.7665228128433228\n"
          ]
        }
      ],
      "source": [
        "sentiment=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sentiment_confidence=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "company=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "company_confidence=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sum_time=0\n",
        "sum_time_2=0\n",
        "for i in range(len(not_preprocessed_data)):\n",
        "  start_time=time.time()\n",
        "  article =f\"\"\"You are a sentiment classification endpoint, classifying given text into: positive, neutral, negative.\n",
        "  Return only the sentiment.\n",
        "  Texts to classify:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "  end_time=time.time()\n",
        "  sum_time+=end_time-start_time\n",
        "  sentiment[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  sentiment_confidence[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(sentiment[i], sentiment_confidence[i])\n",
        "  print(end_time-start_time)\n",
        "\n",
        "  start_time_2=time.time()\n",
        "  article =f\"\"\"You are a NER endpoint, finding names of the companies occuring in the article.\n",
        "  Return only those names. If there are more than one companies, separate each name with ','.\n",
        "  If there will be no company in the article, return 'no company'.\n",
        "\n",
        "  Text:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "  end_time_2=time.time()\n",
        "  sum_time_2+=end_time_2-start_time_2\n",
        "  company[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  company_confidence[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(company[i], company_confidence[i])\n",
        "  print(end_time_2-start_time_2)\n",
        "\n",
        "print(f\"Average time sentiment: {sum_time/len(not_preprocessed_data)}\")\n",
        "print(f\"Average time NER: {sum_time_2/len(not_preprocessed_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h0ms0SiQ31HV"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(columns=['Article', 'Category'])\n",
        "df['Article'] = not_preprocessed_data\n",
        "df['Category'] = answers\n",
        "df['Certainity_category'] = answers_confidence\n",
        "df['Sentiment'] = sentiment\n",
        "df['Certainity_sentiment'] = sentiment_confidence\n",
        "df['Company'] = company\n",
        "df['Certainity_company'] = company_confidence\n",
        "df.to_csv(PATH_TO_SAVE_RESULTS+\"results_4o_mini_logprob.csv\", index=False, sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For GPT-3.5-turbo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCWmTw5W4KE_",
        "outputId": "5553f0de-aa3b-424e-a09a-535ae3a3c45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "human_employee_rights 100.0\n",
            "Negative 93.3\n",
            "Amazon 100.0\n",
            "human_employee_rights 81.5\n",
            "Negative 92.2\n",
            "Starbucks, Workers United, National Labor Relations Board 99.9\n",
            "human_employee_rights 50.0\n",
            "Negative 84.4\n",
            "Amazon 98.2\n",
            "human_employee_rights 98.0\n",
            "Negative 85.3\n",
            "BBC, Hamas 96.4\n",
            "human_employee_rights 100.0\n",
            "Negative 86.6\n",
            "Amazon 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "Negative 79.6\n",
            "BBC, X 99.6\n",
            "diversity_equity_inclusion 100.0\n",
            "Negative 66.1\n",
            "BBC 99.5\n",
            "diversity_equity_inclusion 100.0\n",
            "Neutral 61.8\n",
            "Aviva 100.0\n",
            "environment 97.7\n",
            "Negative 88.7\n",
            "British Museum, BP, Greenpeace, Extinction Rebellion, National Portrait Gallery, Tate, Culture Unstained, Greenpeace UK 60.9\n",
            "environment 100.0\n",
            "Positive 60.3\n",
            "Carbonfuture, Microsoft, Exomad Green 99.4\n",
            "Average time classification: 0.6394724607467651\n",
            "Average time sentiment: 0.9335868835449219\n",
            "Average time NER: 0.6314952135086059\n"
          ]
        }
      ],
      "source": [
        "answers_35=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "answers_confidence_35=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sentiment_35=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sentiment_confidence_35=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "company_35=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "company_confidence_35=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sum_time_class=0\n",
        "sum_time_sent=0\n",
        "sum_time_NER=0\n",
        "for i in range(len(not_preprocessed_data)):\n",
        "  start_time_class=time.time()\n",
        "  article =f\"\"\"You are a text classification endpoint, classifying given text into categories:\n",
        "  human_employee_rights\n",
        "  diversity_equity_inclusion\n",
        "  environment\n",
        "  animal_care\n",
        "  corporate_transparency\n",
        "  business_involvement\n",
        "  political_and_religious_views\n",
        "\n",
        "  If you are not sure, return other.\n",
        "  Return only name of the category.\n",
        "\n",
        "  Texts to classify:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "  end_time_class=time.time()\n",
        "\n",
        "  answers_35[i] = completion.choices[0].message.content\n",
        "  power_35=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  answers_confidence_35[i] = np.round(np.exp(power_35)*100, 1)\n",
        "  print(answers_35[i], answers_confidence_35[i])\n",
        "\n",
        "  start_time_sent=time.time()\n",
        "  article =f\"\"\"You are a sentiment classification endpoint, classifying given text into: positive, neutral, negative.\n",
        "  Return only the sentiment.\n",
        "  Texts to classify:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "    )\n",
        "\n",
        "  end_time_sent=time.time()\n",
        "\n",
        "  sentiment_35[i] = completion.choices[0].message.content\n",
        "  power_35=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  sentiment_confidence_35[i] = np.round(np.exp(power_35)*100, 1)\n",
        "  print(sentiment_35[i], sentiment_confidence_35[i])\n",
        "\n",
        "  start_time_NER=time.time()\n",
        "  article =f\"\"\"You are a NER endpoint, finding names of the companies occuring in the article.\n",
        "  Return only those names. If there are more than one companies, separate each name with ','.\n",
        "  If there will be no company in the article, return 'no company'.\n",
        "\n",
        "  Text:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5\n",
        "  )\n",
        "  end_time_NER=time.time()\n",
        "  company_35[i] = completion.choices[0].message.content\n",
        "  power_35=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  company_confidence_35[i] = np.round(np.exp(power_35)*100, 1)\n",
        "  print(company_35[i], company_confidence_35[i])\n",
        "  sum_time_class+=end_time_class-start_time_class\n",
        "  sum_time_sent+=end_time_sent-start_time_sent\n",
        "  sum_time_NER+=end_time_NER-start_time_NER\n",
        "print(f\"Average time classification: {sum_time_class/len(not_preprocessed_data)}\")\n",
        "print(f\"Average time sentiment: {sum_time_sent/len(not_preprocessed_data)}\")\n",
        "print(f\"Average time NER: {sum_time_NER/len(not_preprocessed_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ynXr-vKFJsMv"
      },
      "outputs": [],
      "source": [
        "df_35 = pd.DataFrame(columns=['Article', 'Category'])\n",
        "df_35['Article'] = not_preprocessed_data\n",
        "df_35['Category']= answers_35\n",
        "df_35['Certainity_category'] = answers_confidence_35\n",
        "df_35['Sentiment'] = sentiment_35\n",
        "df_35['Certainity_sentiment'] = sentiment_confidence_35\n",
        "df_35['Company'] = company_35\n",
        "df_35['Certainity_company'] = company_confidence_35\n",
        "df_35.to_csv(PATH_TO_SAVE_RESULTS+\"results_35_turbo_logprob.csv\", index=False, sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrtEmpQwMHx4"
      },
      "source": [
        "## Comparison of outputs between GPT-3.5-turbo and GPT-4o-mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "processed_4o_data=processed_4o_data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jlr0ak6aQMub",
        "outputId": "c78527d9-60ef-4bb8-a07e-7e63409cb223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "human_employee_rights 100.0\n",
            "human_employee_rights 100.0\n",
            "human_employee_rights 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "human_employee_rights 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "environment 100.0\n",
            "environment 100.0\n"
          ]
        }
      ],
      "source": [
        "answers_cleaned=[\"\" for _ in range(len(processed_4o_data))]\n",
        "answers_confidence_cleaned=[\"\" for _ in range(len(processed_4o_data))]\n",
        "for i in range(len(processed_4o_data)):\n",
        "  article =f\"\"\"You are a text classification endpoint, classifying given text into categories:\n",
        "  human_employee_rights\n",
        "  diversity_equity_inclusion\n",
        "  environment\n",
        "  animal_care\n",
        "  corporate_transparency\n",
        "  business_involvement\n",
        "  political_and_religious_views\n",
        "\n",
        "  If you are not sure, return other.\n",
        "  Return only name of the category.\n",
        "\n",
        "  Texts to classify:\n",
        "\n",
        "  {processed_4o_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "\n",
        "  answers_cleaned[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  answers_confidence_cleaned[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(answers_cleaned[i], answers_confidence_cleaned[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5oPGbioQfx3",
        "outputId": "0ab7e8b3-f536-4586-b1c4-6f9f930ad942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative 88.1\n",
            "Amazon 100.0\n",
            "Neutral 59.0\n",
            "Starbucks, Workers United, NBC Los Angeles, KUOW, The Philadelphia Inquirer, The New York Times, Placer.ai 100.0\n",
            "negative 73.1\n",
            "Amazon, Release, Tripadvisor 99.5\n",
            "neutral 82.1\n",
            "BBC, Hamas, The Times, Israel 100.0\n",
            "negative 85.2\n",
            "Amazon 100.0\n",
            "negative 67.0\n",
            "BBC, GB News, Opera Holland Park, LBC, NCTJ 99.9\n",
            "negative 90.5\n",
            "BBC, The Sunday Telegraph, The Mail, Michelle Obama, Amal Clooney 100.0\n",
            "positive 85.7\n",
            "Aviva, Confederation of British Industry, BP 100.0\n",
            "negative 87.5\n",
            "BP, Greenpeace, National Portrait Gallery, Tate, Culture Unstained 98.6\n",
            "positive 77.7\n",
            "Carbonfuture, Microsoft, Exomad Green 100.0\n"
          ]
        }
      ],
      "source": [
        "sentiment_cleaned=[\"\" for _ in range(len(processed_4o_data))]\n",
        "sentiment_confidence_cleaned=[\"\" for _ in range(len(processed_4o_data))]\n",
        "company_cleaned=[\"\" for _ in range(len(processed_4o_data))]\n",
        "company_confidence_cleaned=[\"\" for _ in range(len(processed_4o_data))]\n",
        "\n",
        "for i in range(len(processed_4o_data)):\n",
        "  article =f\"\"\"You are a sentiment classification endpoint, classifying given text into: positive, neutral, negative.\n",
        "  Return only the sentiment.\n",
        "  Texts to classify:\n",
        "\n",
        "  {processed_4o_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "\n",
        "  sentiment_cleaned[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  sentiment_confidence_cleaned[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(sentiment_cleaned[i], sentiment_confidence_cleaned[i])\n",
        "\n",
        "  article =f\"\"\"You are a NER endpoint, finding names of the companies occuring in the article.\n",
        "  Return only those names. If there are more than one companies, separate each name with ','.\n",
        "  If there will be no company in the article, return 'no company'.\n",
        "\n",
        "  Text:\n",
        "\n",
        "  {processed_4o_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "\n",
        "  company_cleaned[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  company_confidence_cleaned[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(company_cleaned[i], company_confidence_cleaned[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "8wHxeTCnOmKe"
      },
      "outputs": [],
      "source": [
        "df_cleaned = pd.DataFrame(columns=['Article'])\n",
        "df_cleaned['Article'] = processed_4o_data\n",
        "df_cleaned['Category']= answers_cleaned\n",
        "df_cleaned['Certainity_category'] = answers_confidence_cleaned\n",
        "df_cleaned['Sentiment'] = sentiment_cleaned\n",
        "df_cleaned['Certainity_sentiment'] = sentiment_confidence_cleaned\n",
        "df_cleaned['Company'] = company_cleaned\n",
        "df_cleaned['Certainity_company'] = company_confidence_cleaned\n",
        "df_cleaned.to_csv(PATH_TO_SAVE_RESULTS+\"results_4o_after_cleaning_by_4o.csv\", index=False, sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Category</th>\n",
              "      <th>Certainity_category</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Certainity_sentiment</th>\n",
              "      <th>Company</th>\n",
              "      <th>Certainity_company</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>People work in the Amazon Fulfillment Center i...</td>\n",
              "      <td>human_employee_rights</td>\n",
              "      <td>100.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>88.1</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A federal agency is seeking to force Starbucks...</td>\n",
              "      <td>human_employee_rights</td>\n",
              "      <td>100.0</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>59.0</td>\n",
              "      <td>Starbucks, Workers United, NBC Los Angeles, KU...</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You might have seen a new energy drink on Amaz...</td>\n",
              "      <td>human_employee_rights</td>\n",
              "      <td>100.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>73.1</td>\n",
              "      <td>Amazon, Release, Tripadvisor</td>\n",
              "      <td>99.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The BBC's director-general has tried to calm t...</td>\n",
              "      <td>diversity_equity_inclusion</td>\n",
              "      <td>100.0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>82.1</td>\n",
              "      <td>BBC, Hamas, The Times, Israel</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazon is running a competition to give its br...</td>\n",
              "      <td>human_employee_rights</td>\n",
              "      <td>100.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>85.2</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Nihal Arthanayake says he saw 'a lack of diver...</td>\n",
              "      <td>diversity_equity_inclusion</td>\n",
              "      <td>100.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>67.0</td>\n",
              "      <td>BBC, GB News, Opera Holland Park, LBC, NCTJ</td>\n",
              "      <td>99.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The BBC has been slammed after it emerged it i...</td>\n",
              "      <td>diversity_equity_inclusion</td>\n",
              "      <td>100.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>90.5</td>\n",
              "      <td>BBC, The Sunday Telegraph, The Mail, Michelle ...</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The boss of Aviva has revealed senior white ma...</td>\n",
              "      <td>diversity_equity_inclusion</td>\n",
              "      <td>100.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>85.7</td>\n",
              "      <td>Aviva, Confederation of British Industry, BP</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The British Museum has secured a £50m donation...</td>\n",
              "      <td>environment</td>\n",
              "      <td>100.0</td>\n",
              "      <td>negative</td>\n",
              "      <td>87.5</td>\n",
              "      <td>BP, Greenpeace, National Portrait Gallery, Tat...</td>\n",
              "      <td>98.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Carbon removal solutions provider Carbonfuture...</td>\n",
              "      <td>environment</td>\n",
              "      <td>100.0</td>\n",
              "      <td>positive</td>\n",
              "      <td>77.7</td>\n",
              "      <td>Carbonfuture, Microsoft, Exomad Green</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Article  \\\n",
              "0  People work in the Amazon Fulfillment Center i...   \n",
              "1  A federal agency is seeking to force Starbucks...   \n",
              "2  You might have seen a new energy drink on Amaz...   \n",
              "3  The BBC's director-general has tried to calm t...   \n",
              "4  Amazon is running a competition to give its br...   \n",
              "5  Nihal Arthanayake says he saw 'a lack of diver...   \n",
              "6  The BBC has been slammed after it emerged it i...   \n",
              "7  The boss of Aviva has revealed senior white ma...   \n",
              "8  The British Museum has secured a £50m donation...   \n",
              "9  Carbon removal solutions provider Carbonfuture...   \n",
              "\n",
              "                     Category  Certainity_category Sentiment  \\\n",
              "0       human_employee_rights                100.0  negative   \n",
              "1       human_employee_rights                100.0   Neutral   \n",
              "2       human_employee_rights                100.0  negative   \n",
              "3  diversity_equity_inclusion                100.0   neutral   \n",
              "4       human_employee_rights                100.0  negative   \n",
              "5  diversity_equity_inclusion                100.0  negative   \n",
              "6  diversity_equity_inclusion                100.0  negative   \n",
              "7  diversity_equity_inclusion                100.0  positive   \n",
              "8                 environment                100.0  negative   \n",
              "9                 environment                100.0  positive   \n",
              "\n",
              "   Certainity_sentiment                                            Company  \\\n",
              "0                  88.1                                             Amazon   \n",
              "1                  59.0  Starbucks, Workers United, NBC Los Angeles, KU...   \n",
              "2                  73.1                       Amazon, Release, Tripadvisor   \n",
              "3                  82.1                      BBC, Hamas, The Times, Israel   \n",
              "4                  85.2                                             Amazon   \n",
              "5                  67.0        BBC, GB News, Opera Holland Park, LBC, NCTJ   \n",
              "6                  90.5  BBC, The Sunday Telegraph, The Mail, Michelle ...   \n",
              "7                  85.7       Aviva, Confederation of British Industry, BP   \n",
              "8                  87.5  BP, Greenpeace, National Portrait Gallery, Tat...   \n",
              "9                  77.7              Carbonfuture, Microsoft, Exomad Green   \n",
              "\n",
              "   Certainity_company  \n",
              "0               100.0  \n",
              "1               100.0  \n",
              "2                99.5  \n",
              "3               100.0  \n",
              "4               100.0  \n",
              "5                99.9  \n",
              "6               100.0  \n",
              "7               100.0  \n",
              "8                98.6  \n",
              "9               100.0  "
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_gt=df_gt[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjuKn41OMLeK",
        "outputId": "53aa7670-e01e-4508-822d-dfc902e8e25e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of the same categories returned by 4o mini and 3.5 turbo: 9.\n",
            "Number of the same categories returned by 4o mini and me: 9.\n",
            "Number of the same categories returned by 3.5 turbo and me: 9.\n",
            "Number of the same categories returned by 4o after cleaning by 4o and me: 9.\n",
            "Number of the same sentiments returned by 4o mini and 3.5 turbo: 0.\n",
            "Number of the same sentiments returned by 4o mini and me: 7.\n",
            "Number of the same sentiments returned by 3.5 turbo and me: 0.\n",
            "Number of the same sentiments returned by 4o after cleaning by 4o and me: 8.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of the same categories returned by 4o mini and 3.5 turbo: {np.sum(df['Category']==df_35['Category'])}.\")\n",
        "print(f\"Number of the same categories returned by 4o mini and me: {np.sum(df['Category']==df_gt['Category'])}.\")\n",
        "print(f\"Number of the same categories returned by 3.5 turbo and me: {np.sum(df_35['Category']==df_gt['Category'])}.\")\n",
        "print(f\"Number of the same categories returned by 4o after cleaning by 4o and me: {np.sum(df_cleaned['Category']==df_gt['Category'])}.\")\n",
        "\n",
        "print(f\"Number of the same sentiments returned by 4o mini and 3.5 turbo: {np.sum(df['Sentiment']==df_35['Sentiment'])}.\")\n",
        "print(f\"Number of the same sentiments returned by 4o mini and me: {np.sum(df['Sentiment']==df_gt['Sentiment'])}.\")\n",
        "print(f\"Number of the same sentiments returned by 3.5 turbo and me: {np.sum(df_35['Sentiment']==df_gt['Sentiment'])}.\")\n",
        "print(f\"Number of the same sentiments returned by 4o after cleaning by 4o and me: {np.sum(df_cleaned['Sentiment']==df_gt['Sentiment'])}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gkb7BikFaLt"
      },
      "source": [
        "## Analysis for articles cleaned with regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxEAEJbQFVm9",
        "outputId": "1b796f5a-ed7d-40dc-d5f3-433025659aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "human_employee_rights 100.0\n",
            "human_employee_rights 100.0\n",
            "human_employee_rights 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "human_employee_rights 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "diversity_equity_inclusion 100.0\n",
            "environment 100.0\n",
            "environment 100.0\n"
          ]
        }
      ],
      "source": [
        "answers_cleaned=[\"\" for _ in range(len(processed_regex_data))]\n",
        "answers_confidence_cleaned=[\"\" for _ in range(len(processed_regex_data))]\n",
        "for i in range(len(processed_regex_data)):\n",
        "  article =f\"\"\"You are a text classification endpoint, classifying given text into categories:\n",
        "  human_employee_rights\n",
        "  diversity_equity_inclusion\n",
        "  environment\n",
        "  animal_care\n",
        "  corporate_transparency\n",
        "  business_involvement\n",
        "  political_and_religious_views\n",
        "\n",
        "  If you are not sure, return other.\n",
        "  Return only name of the category.\n",
        "\n",
        "  Texts to classify:\n",
        "\n",
        "  {processed_regex_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "\n",
        "  answers_cleaned[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  answers_confidence_cleaned[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(answers_cleaned[i], answers_confidence_cleaned[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M5-0oAHFipA",
        "outputId": "8e05241b-dad5-4b55-efdf-3995a95cdf8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "negative 73.1\n",
            "Amazon 100.0\n",
            "neutral 58.7\n",
            "Starbucks, Workers United, NBC Los Angeles, KUOW, The Philadelphia Inquirer, The New York Times, Placer.ai 100.0\n",
            "negative 95.0\n",
            "Amazon, Tripadvisor, Microsoft 99.5\n",
            "neutral 93.5\n",
            "BBC, Hamas, The Times, Israel 100.0\n",
            "negative 92.4\n",
            "Amazon 100.0\n",
            "Negative 56.1\n",
            "BBC, GB News, LBC, Opera Holland Park, NCTJ, MailOnline 100.0\n",
            "negative 90.5\n",
            "BBC, Reform UK, Free Speech Union 100.0\n",
            "neutral 39.3\n",
            "Aviva, BP, CBI, AXA, Zurich 100.0\n",
            "negative 53.5\n",
            "BP, Greenpeace, National Portrait Gallery, Tate, Culture Unstained 99.8\n",
            "positive 97.7\n",
            "Carbonfuture, Microsoft, Exomad Green 100.0\n"
          ]
        }
      ],
      "source": [
        "sentiment_cleaned=[\"\" for _ in range(len(processed_regex_data))]\n",
        "sentiment_confidence_cleaned=[\"\" for _ in range(len(processed_regex_data))]\n",
        "company_cleaned=[\"\" for _ in range(len(processed_regex_data))]\n",
        "company_confidence_cleaned=[\"\" for _ in range(len(processed_regex_data))]\n",
        "\n",
        "for i in range(len(processed_regex_data)):\n",
        "  article =f\"\"\"You are a sentiment classification endpoint, classifying given text into: positive, neutral, negative.\n",
        "  Return only the sentiment.\n",
        "  Texts to classify:\n",
        "\n",
        "  {processed_regex_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "\n",
        "  sentiment_cleaned[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  sentiment_confidence_cleaned[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(sentiment_cleaned[i], sentiment_confidence_cleaned[i])\n",
        "\n",
        "  article =f\"\"\"You are a NER endpoint, finding names of the companies occuring in the article.\n",
        "  Return only those names. If there are more than one companies, separate each name with ','.\n",
        "  If there will be no company in the article, return 'no company'.\n",
        "\n",
        "  Text:\n",
        "\n",
        "  {processed_regex_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "\n",
        "  company_cleaned[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  company_confidence_cleaned[i] = np.round(np.exp(power)*100, 1)\n",
        "  print(company_cleaned[i], company_confidence_cleaned[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "C58ppPn2FzCO"
      },
      "outputs": [],
      "source": [
        "df_cleaned_regex = pd.DataFrame(columns=['Article'])\n",
        "df_cleaned_regex['Article'] = processed_regex_data\n",
        "df_cleaned_regex['Category']= answers_cleaned\n",
        "df_cleaned_regex['Certainity_category'] = answers_confidence_cleaned\n",
        "df_cleaned_regex['Sentiment'] = sentiment_cleaned\n",
        "df_cleaned_regex['Certainity_sentiment'] = sentiment_confidence_cleaned\n",
        "df_cleaned_regex['Company'] = company_cleaned\n",
        "df_cleaned_regex['Certainity_company'] = company_confidence_cleaned\n",
        "df_cleaned_regex.to_csv(PATH_TO_SAVE_RESULTS+\"results_4o_after_cleaning_regex.csv\", index=False, sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6tjz-uSF9Tx",
        "outputId": "6e28a90c-1359-490e-bdd5-63df61402efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of the same categories returned by 4o mini after regex cleaning and me: 9.\n",
            "Number of the same sentiments returned by 4o mini after regex cleaning and me: 6.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of the same categories returned by 4o mini after regex cleaning and me: {np.sum(df_cleaned_regex['Category']==df_gt['Category'])}.\")\n",
        "\n",
        "print(f\"Number of the same sentiments returned by 4o mini after regex cleaning and me: {np.sum(df_cleaned_regex['Sentiment']==df_gt['Sentiment'])}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGyEC2lt2Rk6"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Conduct experiments\n",
        "For each of the prepared subsets, the experiments and evaluation were conducted for all three tasks: category recognition, sentiment analysis and company recognition. The results were later manually analyzed and described in the work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg0BD9g96Rvn",
        "outputId": "9e1c8867-2999-457d-cd86-acc73514a524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lists created.\n",
            "notpreprocessed number 0 category done.\n",
            "notpreprocessed number 0 sentiment done.\n",
            "notpreprocessed number 0 company done.\n",
            "notpreprocessed number 1 category done.\n",
            "notpreprocessed number 1 sentiment done.\n",
            "notpreprocessed number 1 company done.\n",
            "notpreprocessed number 2 category done.\n",
            "notpreprocessed number 2 sentiment done.\n",
            "notpreprocessed number 2 company done.\n",
            "Asking model done.\n",
            "Score for notpreprocessed data for category for gpt-3.5-turbo is 41.666666666666664.\n",
            "Score for notpreprocessed for sentiment for gpt-3.5-turbo is 67.0.\n",
            "Score for notpreprocessed for company for gpt-3.5-turbo is 3.0.\n",
            "1. Not processed GPT 3.5 DONE\n",
            "Lists created.\n",
            "notpreprocessed number 0 category done.\n",
            "notpreprocessed number 0 sentiment done.\n",
            "notpreprocessed number 0 company done.\n",
            "notpreprocessed number 1 category done.\n",
            "notpreprocessed number 1 sentiment done.\n",
            "notpreprocessed number 1 company done.\n",
            "notpreprocessed number 2 category done.\n",
            "notpreprocessed number 2 sentiment done.\n",
            "notpreprocessed number 2 company done.\n",
            "Asking model done.\n",
            "Score for notpreprocessed data for category for gpt-4o-mini is 51.666666666666664.\n",
            "Score for notpreprocessed for sentiment for gpt-4o-mini is 72.0.\n",
            "Score for notpreprocessed for company for gpt-4o-mini is 3.0.\n",
            "2. Not processed GPT 4o DONE\n"
          ]
        }
      ],
      "source": [
        "# 1. Not processed GPT 3.5\n",
        "\n",
        "conduct_experiments(not_preprocessed_data, type_of_data=\"notpreprocessed\", which_model=\"gpt-3.5-turbo\", exp_number=3)\n",
        "print(\"1. Not processed GPT 3.5 DONE\")\n",
        "\n",
        "# 2. Not processed GPT 4o\n",
        "\n",
        "conduct_experiments(not_preprocessed_data, type_of_data=\"notpreprocessed\", which_model=\"gpt-4o-mini\", exp_number=4)\n",
        "print(\"2. Not processed GPT 4o DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWrpUO8OgC5i",
        "outputId": "da7fe395-489b-449b-f072-3f02a0e7b4d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lists created.\n",
            "processed_by_4o number 0 category done.\n",
            "processed_by_4o number 0 sentiment done.\n",
            "processed_by_4o number 0 company done.\n",
            "processed_by_4o number 1 category done.\n",
            "processed_by_4o number 1 sentiment done.\n",
            "processed_by_4o number 1 company done.\n",
            "processed_by_4o number 2 category done.\n",
            "processed_by_4o number 2 sentiment done.\n",
            "processed_by_4o number 2 company done.\n",
            "Asking model done.\n",
            "Score for processed_by_4o data for category for gpt-3.5-turbo is 42.666666666666664.\n",
            "Score for processed_by_4o for sentiment for gpt-3.5-turbo is 65.33333333333333.\n",
            "Score for processed_by_4o for company for gpt-3.5-turbo is 3.0.\n",
            "3. Processed by GPT 4o, now GPT 3.5 DONE\n",
            "Lists created.\n",
            "processed_by_4o number 0 category done.\n",
            "processed_by_4o number 0 sentiment done.\n",
            "processed_by_4o number 0 company done.\n",
            "processed_by_4o number 1 category done.\n",
            "processed_by_4o number 1 sentiment done.\n",
            "processed_by_4o number 1 company done.\n",
            "processed_by_4o number 2 category done.\n",
            "processed_by_4o number 2 sentiment done.\n",
            "processed_by_4o number 2 company done.\n",
            "Asking model done.\n",
            "Score for processed_by_4o data for category for gpt-4o-mini is 51.333333333333336.\n",
            "Score for processed_by_4o for sentiment for gpt-4o-mini is 72.66666666666667.\n",
            "Score for processed_by_4o for company for gpt-4o-mini is 3.0.\n",
            "4. Processed by GPT 4o, now GPT 4o DONE\n"
          ]
        }
      ],
      "source": [
        "# 3. Processed by GPT 4o, now GPT 3.5\n",
        "\n",
        "conduct_experiments(processed_4o_data, type_of_data=\"processed_by_4o\", which_model=\"gpt-3.5-turbo\", exp_number=5)\n",
        "print(\"3. Processed by GPT 4o, now GPT 3.5 DONE\")\n",
        "\n",
        "# 4. Processed by GPT 4o, now GPT 4o\n",
        "\n",
        "conduct_experiments(processed_4o_data, type_of_data=\"processed_by_4o\", which_model=\"gpt-4o-mini\", exp_number=6)\n",
        "print(\"4. Processed by GPT 4o, now GPT 4o DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtFgLTwqcbq7",
        "outputId": "0b0cca31-2323-4bc3-e865-aae2e4c4faff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lists created.\n",
            "processed_with_regex number 0 category done.\n",
            "processed_with_regex number 0 sentiment done.\n",
            "processed_with_regex number 0 company done.\n",
            "processed_with_regex number 1 category done.\n",
            "processed_with_regex number 1 sentiment done.\n",
            "processed_with_regex number 1 company done.\n",
            "processed_with_regex number 2 category done.\n",
            "processed_with_regex number 2 sentiment done.\n",
            "processed_with_regex number 2 company done.\n",
            "Asking model done.\n",
            "Score for processed_with_regex data for category for gpt-3.5-turbo is 41.666666666666664.\n",
            "Score for processed_with_regex for sentiment for gpt-3.5-turbo is 66.33333333333333.\n",
            "Score for processed_with_regex for company for gpt-3.5-turbo is 3.0.\n",
            "5. Processed with regex, now GPT 3.5 DONE\n",
            "Lists created.\n",
            "processed_with_regex number 0 category done.\n",
            "processed_with_regex number 0 sentiment done.\n",
            "processed_with_regex number 0 company done.\n",
            "processed_with_regex number 1 category done.\n",
            "processed_with_regex number 1 sentiment done.\n",
            "processed_with_regex number 1 company done.\n",
            "processed_with_regex number 2 category done.\n",
            "processed_with_regex number 2 sentiment done.\n",
            "processed_with_regex number 2 company done.\n",
            "Asking model done.\n",
            "Score for processed_with_regex data for category for gpt-4o-mini is 51.666666666666664.\n",
            "Score for processed_with_regex for sentiment for gpt-4o-mini is 75.0.\n",
            "Score for processed_with_regex for company for gpt-4o-mini is 3.0.\n",
            "6. Processed with regex, now GPT 4o DONE\n"
          ]
        }
      ],
      "source": [
        "# 5. Processed with regex, now GPT 3.5\n",
        "\n",
        "conduct_experiments(processed_regex_data, type_of_data=\"processed_with_regex\", which_model=\"gpt-3.5-turbo\", exp_number=7)\n",
        "print(\"5. Processed with regex, now GPT 3.5 DONE\")\n",
        "\n",
        "# 6. Processed with regex, now GPT 4o\n",
        "\n",
        "conduct_experiments(processed_regex_data, type_of_data=\"processed_with_regex\", which_model=\"gpt-4o-mini\", exp_number=8)\n",
        "print(\"6. Processed with regex, now GPT 4o DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SJU9EOzgI2x",
        "outputId": "a7d2f980-fa15-454f-eb23-55047a39d8f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lists created.\n",
            "processed_by_human number 0 category done.\n",
            "processed_by_human number 0 sentiment done.\n",
            "processed_by_human number 0 company done.\n",
            "processed_by_human number 1 category done.\n",
            "processed_by_human number 1 sentiment done.\n",
            "processed_by_human number 1 company done.\n",
            "processed_by_human number 2 category done.\n",
            "processed_by_human number 2 sentiment done.\n",
            "processed_by_human number 2 company done.\n",
            "Asking model done.\n",
            "Score for processed_by_human data for category for gpt-3.5-turbo is 42.333333333333336.\n",
            "Score for processed_by_human for sentiment for gpt-3.5-turbo is 65.33333333333333.\n",
            "Score for processed_by_human for company for gpt-3.5-turbo is 3.0.\n",
            "7. Processed by human_annotator, now GPT 3.5 DONE\n",
            "Lists created.\n",
            "processed_by_human number 0 category done.\n",
            "processed_by_human number 0 sentiment done.\n",
            "processed_by_human number 0 company done.\n",
            "processed_by_human number 1 category done.\n",
            "processed_by_human number 1 sentiment done.\n",
            "processed_by_human number 1 company done.\n",
            "processed_by_human number 2 category done.\n",
            "processed_by_human number 2 sentiment done.\n",
            "processed_by_human number 2 company done.\n",
            "Asking model done.\n",
            "Score for processed_by_human data for category for gpt-4o-mini is 50.0.\n",
            "Score for processed_by_human for sentiment for gpt-4o-mini is 73.0.\n",
            "Score for processed_by_human for company for gpt-4o-mini is 3.0.\n",
            "8. Processed by human_annotator, now GPT 4o DONE\n"
          ]
        }
      ],
      "source": [
        "# 7. Processed by human_annotator, now GPT 3.5\n",
        "\n",
        "conduct_experiments(processed_human_data, type_of_data=\"processed_by_human\", which_model=\"gpt-3.5-turbo\", exp_number=9)\n",
        "print(\"7. Processed by human_annotator, now GPT 3.5 DONE\")\n",
        "\n",
        "# 8. Processed by human_annotator, now GPT 4o\n",
        "\n",
        "conduct_experiments(processed_human_data, type_of_data=\"processed_by_human\", which_model=\"gpt-4o-mini\", exp_number=10)\n",
        "print(\"8. Processed by human_annotator, now GPT 4o DONE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxnDE8cBNuBP"
      },
      "source": [
        "## Experiments for incidents recognition\n",
        "The pipeline for incident recognition is similar as for other tasks presented above. The only difference is that it is unsupervised task, therefore the evaluation was different.\n",
        "The results were not described in the work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0ZwgxWhNvLZ",
        "outputId": "4293d041-71c3-47df-c399-63e52751666c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workplace bullying incident 89.3 0.67862868309021\n",
            "Labor dispute escalation 77.7 0.5191090106964111\n",
            "Worker exploitation allegations 80.4 0.5036749839782715\n",
            "Workplace tensions 98.6 0.5653071403503418\n",
            "Worker protests Amazon 85.2 0.6032676696777344\n",
            "Workplace racism 63.6 0.5277941226959229\n",
            "Diversity spending controversy 54.3 0.8049933910369873\n",
            "Sexism in finance 99.9 0.5860962867736816\n",
            "Environmental protest 93.9 1.0483601093292236\n",
            "Carbon removal agreement 100.0 0.6526217460632324\n",
            "Greenwashing investigation 99.5 0.5971922874450684\n",
            "Telehealth expansion 28.8 1.1860978603363037\n",
            "Food recall incident 73.1 0.9719581604003906\n",
            "Grocery delivery service 96.5 0.5075788497924805\n",
            "Grocery price concerns 96.2 0.5102365016937256\n",
            "Food waste incident 100.0 0.7876942157745361\n",
            "Food donation initiative 99.9 0.48348164558410645\n",
            "Discrimination complaint filed 54.9 0.47858095169067383\n",
            "Bribery charges Switzerland 98.0 0.5533983707427979\n",
            "PPE contract scandal 96.0 0.564786434173584\n",
            "Misleading advertisements 95.7 0.5305430889129639\n",
            "Advertising boycott 62.6 0.6224913597106934\n",
            "Banking climate exit 56.2 1.2031595706939697\n",
            "Mining project opposition 69.2 0.8726413249969482\n",
            "Burglary incident 86.8 0.7295773029327393\n",
            "Unauthorized parties ban 75.8 1.1182756423950195\n",
            "Dealership buyouts 98.6 0.5981266498565674\n",
            "Sanctions violations 100.0 0.3999049663543701\n",
            "Cybersecurity review 100.0 0.5160021781921387\n",
            "Factory construction talks 87.3 0.4363377094268799\n",
            "U.S. TikTok ban 44.5 0.8329999446868896\n",
            "Record net profit 91.5 0.5009593963623047\n",
            "Controversial Eurovision selection 44.4 0.9164891242980957\n",
            "Anti-Semitic comments 84.6 0.714130163192749\n",
            "Advertising boycott, anti-Semitism 82.0 0.8189752101898193\n",
            "Employee attendance restriction 72.6 0.48626184463500977\n",
            "International sports exclusion 30.9 0.4566187858581543\n",
            "Sports exclusion policy 57.9 0.4920084476470947\n",
            "Water governance conflict 57.5 0.4637134075164795\n",
            "Safety incidents 99.6 0.47362685203552246\n",
            "Serious misconduct 41.8 0.3933093547821045\n",
            "Parking fee increases 99.8 0.509678840637207\n",
            "Tax dispute resolution 100.0 0.48866772651672363\n",
            "Antitrust verdict 95.2 0.4569742679595947\n",
            "Interchange fee cap 88.2 0.4663677215576172\n",
            "Manufacturing shift 26.1 0.6761078834533691\n",
            "Production cutback 99.2 0.8054680824279785\n",
            "Device theft prevention 44.3 0.5034084320068359\n",
            "Viewership statistics revealed 48.4 0.9756991863250732\n",
            "Sexual assault case 99.8 0.6031851768493652\n",
            "AI job displacement 67.6 0.4774777889251709\n",
            "Mortgage discrimination probe 78.8 0.5526564121246338\n",
            "Uniform controversy incident 99.8 0.7675244808197021\n",
            "Electric vehicle announcement 88.0 0.48764848709106445\n",
            "Rat infestation allegations 98.8 0.8046483993530273\n",
            "Shipping disruptions. 92.2 0.47308969497680664\n",
            "Sexual harassment probe 99.9 0.47120189666748047\n",
            "Forced labor lawsuit 99.8 0.5640943050384521\n",
            "BBC scandal inquiry 89.8 0.7342038154602051\n",
            "Classified document leak 91.6 0.7653212547302246\n",
            "Decarbonization investment opportunities 48.4 0.5305490493774414\n",
            "Labor negotiations ongoing 94.0 0.6320035457611084\n",
            "Wireless charging development 99.4 1.0485785007476807\n",
            "Supply chain management 98.9 0.4908285140991211\n",
            "Sustainability initiative launched 55.0 0.7544877529144287\n",
            "Labor policy change 37.4 0.9754745960235596\n",
            "Record jet deal 29.6 0.8178391456604004\n",
            "No incident 38.6 0.5500576496124268\n",
            "Assistance request 76.7 0.6263217926025391\n",
            "Chip shortage incident 84.9 0.591242790222168\n",
            "A.I. security concerns 80.5 0.8285315036773682\n",
            "Carbon removal initiative 99.8 0.5505039691925049\n",
            "Climate change impact 95.3 0.618859052658081\n",
            "Antitrust concerns 94.1 0.4850637912750244\n",
            "Corporate collaboration announcement 44.9 0.43152928352355957\n",
            "Binance settlement issues 85.0 1.027214527130127\n",
            "Brexit impact concerns 72.8 0.43589091300964355\n",
            "Bhopal Gas Tragedy 100.0 0.8211119174957275\n",
            "Electric car production 48.9 0.5482323169708252\n",
            "NHL mask controversy 72.1 0.638418436050415\n",
            "Media Bias Accusations 96.8 0.6771843433380127\n",
            "Royalty model changes 99.5 0.4689168930053711\n",
            "Wheelchair mishandling incident 76.9 0.8788356781005859\n",
            "Coastal erosion 99.9 0.9692099094390869\n",
            "Gender bias apology 99.4 0.5254061222076416\n",
            "Transgender inclusion controversy 80.0 0.6838521957397461\n",
            "Stock sale incident 94.6 0.4853982925415039\n",
            "Manufacturing incentives scheme 92.8 0.620539665222168\n",
            "Profit increase 83.9 0.5228242874145508\n",
            "Fraud prevention partnership 98.9 0.6237471103668213\n",
            "Rank hypocrisy accusations 34.6 0.636437177658081\n",
            "Texting improvements announced 72.1 0.5692043304443359\n",
            "Return-to-office mandate 81.5 0.5704686641693115\n",
            "Antisemitic conspiracy theory 99.6 0.5592479705810547\n",
            "Starbucks employee walkout 99.6 0.5073122978210449\n",
            "Hybrid transition announcement 87.0 0.7279300689697266\n",
            "Financial performance report 70.4 0.8938946723937988\n",
            "Greenwashing accusation 100.0 0.4069175720214844\n",
            "Scam alert warning 62.8 0.41897034645080566\n",
            "Fossil-free steel 82.3 0.45154738426208496\n",
            "Average time: 0.6389101862907409\n"
          ]
        }
      ],
      "source": [
        "df_incidents = pd.DataFrame(columns=['Article', 'Incident', 'Confidence','Time', 'Incident_2', 'Confidence_2', 'Time_2', 'Incident_3', 'Confidence_3', 'Time_3'])\n",
        "df_incidents['Article'] = not_preprocessed_data\n",
        "answers=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "answers_confidence=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sum_time=0\n",
        "for i in range(len(not_preprocessed_data)):\n",
        "  start_time=time.time()\n",
        "  article =f\"\"\"You are an incident recognition endpoint, for each given text return incident. Your answer cannot be longer than 3 words.\n",
        "\n",
        "  Text:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "  end_time=time.time()\n",
        "  answers[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  answers_confidence[i] = np.round(np.exp(power)*100, 1)\n",
        "  sum_time+=end_time-start_time\n",
        "  print(answers[i], answers_confidence[i], end_time-start_time)\n",
        "\n",
        "df_incidents['Incident']= answers\n",
        "df_incidents['Confidence']= answers_confidence\n",
        "df_incidents['Time']=end_time-start_time\n",
        "print(f\"Average time: {sum_time/len(not_preprocessed_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUHw6z0_X8rl",
        "outputId": "6bce5132-7e63-4dd6-bbae-37a88d84013c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workplace bullying incident 81.0 0.7966446876525879\n",
            "Labor dispute escalation 77.7 0.7581255435943604\n",
            "Worker exploitation allegations 80.2 0.5566978454589844\n",
            "Workplace tensions 98.6 0.9661712646484375\n",
            "Worker exploitation 87.9 0.7535190582275391\n",
            "Workplace racism 63.6 0.4298710823059082\n",
            "Diversity spending controversy 54.3 0.7015550136566162\n",
            "Sexism in finance 99.9 0.7589480876922607\n",
            "Environmental protest 94.2 0.9662995338439941\n",
            "Carbon removal agreement 100.0 0.4668853282928467\n",
            "Greenwashing investigation 99.5 0.5280771255493164\n",
            "Telehealth expansion 28.1 0.9538311958312988\n",
            "Food recall incident 62.2 1.001758337020874\n",
            "Grocery delivery service 95.8 0.37368011474609375\n",
            "Grocery price concerns 94.5 0.5318479537963867\n",
            "Food waste incident 100.0 0.5200080871582031\n",
            "Food donation initiative 99.9 0.4218144416809082\n",
            "Discrimination complaint filed 48.6 0.4254434108734131\n",
            "Bribery charges Switzerland 98.0 0.5660936832427979\n",
            "PPE contract scandal 93.8 0.7977972030639648\n",
            "Misleading advertisements 94.9 0.47112393379211426\n",
            "Advertising boycott X 66.5 0.4384727478027344\n",
            "Banking sector exit 56.2 1.3682849407196045\n",
            "Mining project opposition 74.3 0.661116361618042\n",
            "Burglary incident 88.8 0.6902139186859131\n",
            "Unauthorized parties ban 70.7 1.0712857246398926\n",
            "Dealership buyouts 98.6 0.6821348667144775\n",
            "Sanctions violations 100.0 0.5978994369506836\n",
            "Cybersecurity review 100.0 0.4477376937866211\n",
            "Factory construction talks 90.1 0.4784219264984131\n",
            "U.S. TikTok ban 43.9 0.8049767017364502\n",
            "Record net profit 94.4 0.4343442916870117\n",
            "Controversial Eurovision selection 45.0 0.835273265838623\n",
            "Anti-Semitic comments 84.6 0.5310256481170654\n",
            "Advertising boycott, anti-Semitism 84.6 0.7262029647827148\n",
            "Employee attendance restriction 72.6 0.4780611991882324\n",
            "International sports exclusion 31.0 0.5119454860687256\n",
            "Sports exclusion policy 57.9 0.37519168853759766\n",
            "Water governance conflict 54.3 0.534315824508667\n",
            "Safety incidents 99.8 0.6032867431640625\n",
            "Serious misconduct 41.8 0.43226027488708496\n",
            "Parking fee increase 99.9 0.4954395294189453\n",
            "Tax dispute resolution 100.0 0.583207368850708\n",
            "Antitrust verdict 95.2 0.4617605209350586\n",
            "Interchange fee cap 90.5 0.39945054054260254\n",
            "Industry transformation 22.7 0.5782115459442139\n",
            "Production cutback 98.9 1.271054744720459\n",
            "Device theft prevention 42.9 0.4044175148010254\n",
            "Viewership statistics revealed 48.4 0.9800689220428467\n",
            "Sexual assault case 99.8 0.7088212966918945\n",
            "AI job displacement 61.9 0.6826498508453369\n",
            "Mortgage discrimination probe 78.8 1.2967798709869385\n",
            "Uniform controversy incident 99.8 0.8722670078277588\n",
            "Electric vehicle announcement 88.0 0.4171411991119385\n",
            "Rat infestation allegations 98.5 0.5473098754882812\n",
            "Shipping disruptions. 92.2 0.6593072414398193\n",
            "Sexual harassment probe 99.9 0.35576772689819336\n",
            "Forced labor lawsuit 99.8 0.576667308807373\n",
            "BBC scandal inquiry 89.8 0.8345904350280762\n",
            "Classified document leak 91.6 2.001091480255127\n",
            "Decarbonization investment opportunities 46.5 0.6728172302246094\n",
            "Labor negotiations ongoing 96.3 0.5180649757385254\n",
            "Wireless charging development 99.4 0.9684596061706543\n",
            "Supply chain management 98.9 0.5302965641021729\n",
            "Sustainability initiative launched 55.0 0.51495361328125\n",
            "Labor policy change 37.4 0.6701273918151855\n",
            "Record jet deal 29.6 0.8598403930664062\n",
            "No incident 38.6 0.4094266891479492\n",
            "Assisted conversation request 74.9 0.4299337863922119\n",
            "Chip shortage incident 90.9 0.4947984218597412\n",
            "A.I. security concerns 84.0 0.6084785461425781\n",
            "Carbon removal initiative 99.8 0.46679258346557617\n",
            "Climate change impact 95.3 0.41301584243774414\n",
            "Antitrust concerns 93.0 0.4644968509674072\n",
            "Corporate collaboration announcement 45.7 0.38001203536987305\n",
            "Binance settlement issues 85.0 0.8661272525787354\n",
            "Brexit impact concerns 75.8 0.4896416664123535\n",
            "Bhopal Gas Tragedy 100.0 0.7278664112091064\n",
            "Electric car production 48.9 0.4121694564819336\n",
            "NHL mask controversy 79.1 0.45821595191955566\n",
            "Media Bias Accusations 97.2 0.6883580684661865\n",
            "Royalty model changes 99.5 0.5130517482757568\n",
            "Wheelchair mishandling incident 77.1 0.806429386138916\n",
            "Coastal erosion 99.9 1.009946346282959\n",
            "Gender bias apology 99.6 0.42241930961608887\n",
            "Transgender inclusion controversy 80.0 1.051098346710205\n",
            "Stock sale incident 95.2 0.5039548873901367\n",
            "Manufacturing incentives scheme 92.8 0.5297284126281738\n",
            "Profit increase 85.8 0.4868745803833008\n",
            "Fraud prevention partnership 98.9 0.6540238857269287\n",
            "Rank hypocrisy accusations 43.9 0.6979489326477051\n",
            "Texting improvements announced 72.1 0.4777219295501709\n",
            "Return-to-office mandate 81.5 0.3815882205963135\n",
            "Antisemitic conspiracy theory 99.6 0.5826277732849121\n",
            "Starbucks employee walkout 99.6 1.3318839073181152\n",
            "Hybrid transition announcement 83.9 0.4957849979400635\n",
            "Financial performance report 71.5 0.8904588222503662\n",
            "Greenwashing accusation 100.0 1.4255263805389404\n",
            "Scam alert 56.1 0.42061543464660645\n",
            "Fossil-free steel 74.6 0.4593372344970703\n",
            "Average time: 0.657595624923706\n"
          ]
        }
      ],
      "source": [
        "answers=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "answers_confidence=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sum_time=0\n",
        "for i in range(len(not_preprocessed_data)):\n",
        "  start_time=time.time()\n",
        "  article =f\"\"\"You are an incident recognition endpoint, for each given text return incident. Your answer cannot be longer than 3 words.\n",
        "\n",
        "  Text:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "  end_time=time.time()\n",
        "  answers[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  answers_confidence[i] = np.round(np.exp(power)*100, 1)\n",
        "  sum_time+=end_time-start_time\n",
        "  print(answers[i], answers_confidence[i], end_time-start_time)\n",
        "\n",
        "df_incidents['Incident_2']= answers\n",
        "df_incidents['Confidence_2']=answers_confidence\n",
        "df_incidents['Time_2']=end_time-start_time\n",
        "print(f\"Average time: {sum_time/len(not_preprocessed_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTw0K6xcX8yS",
        "outputId": "1737a1dc-fb69-4cc0-aa66-36518fd5f4f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Workplace bullying incident 81.0 1.2986400127410889\n",
            "Labor dispute escalation 73.0 0.4606778621673584\n",
            "Worker exploitation allegations 80.2 0.5183687210083008\n",
            "Workplace tensions 98.6 0.7458746433258057\n",
            "Worker exploitation 87.9 0.5177152156829834\n",
            "Workplace racism 63.6 0.6620256900787354\n",
            "Diversity spending controversy 46.0 0.7685351371765137\n",
            "Sexism in finance 99.9 0.679248571395874\n",
            "Environmental protest 92.6 0.9188222885131836\n",
            "Carbon removal agreement 100.0 2.672606945037842\n",
            "Greenwashing investigation 99.5 0.4577467441558838\n",
            "Telehealth expansion 28.8 1.2005720138549805\n",
            "Food recall incident 62.2 1.0598440170288086\n",
            "Grocery delivery service 95.9 0.362396240234375\n",
            "Grocery price concerns 94.5 2.1176507472991943\n",
            "Food waste incident 100.0 0.4573543071746826\n",
            "Food donation initiative 99.9 0.4730827808380127\n",
            "Discrimination complaint filed 54.9 1.9974400997161865\n",
            "Bribery charges Switzerland 98.0 0.5793232917785645\n",
            "PPE contract scandal 93.8 0.9059092998504639\n",
            "Misleading advertisements 96.6 0.6415693759918213\n",
            "Advertising boycott X 66.5 0.5504074096679688\n",
            "Banking climate exit 56.2 1.7970967292785645\n",
            "Mining project opposition 74.3 0.5553121566772461\n",
            "Burglary incident 88.8 0.6334114074707031\n",
            "Unauthorized parties ban 70.7 0.6515302658081055\n",
            "Dealership buyouts 98.6 0.5001378059387207\n",
            "Sanctions violations 100.0 0.5061545372009277\n",
            "Cybersecurity review 100.0 0.7445521354675293\n",
            "Factory construction talks 90.1 0.5342025756835938\n",
            "U.S. TikTok ban 43.9 0.855971097946167\n",
            "Record net profit 94.4 0.6187863349914551\n",
            "Controversial Eurovision selection 45.0 1.0881459712982178\n",
            "Anti-Semitic comments 80.3 0.6161315441131592\n",
            "Advertising boycott, anti-Semitism 84.6 0.8334400653839111\n",
            "Employee attendance restriction 75.0 0.4985475540161133\n",
            "International sports exclusion 30.1 0.39264631271362305\n",
            "Sports exclusion policy 55.1 0.6097450256347656\n",
            "Water governance conflict 57.5 0.5736663341522217\n",
            "Safety incidents 99.6 0.49921345710754395\n",
            "Serious misconduct 41.8 0.5200746059417725\n",
            "Parking fee increases 99.9 0.6154084205627441\n",
            "Tax dispute resolution 100.0 0.6171047687530518\n",
            "Antitrust verdict 95.2 0.6114354133605957\n",
            "Interchange fee cap 88.1 0.45006847381591797\n",
            "Manufacturing shift 26.1 0.6828510761260986\n",
            "Production cutback 98.9 1.250927448272705\n",
            "Device theft prevention 42.9 0.5295882225036621\n",
            "Viewership statistics revealed 48.4 0.9814884662628174\n",
            "Sexual assault case 99.8 0.6906101703643799\n",
            "AI job displacement 67.6 0.8633403778076172\n",
            "Mortgage discrimination probe 72.5 0.5221781730651855\n",
            "Uniform controversy incident 99.8 1.530055284500122\n",
            "Electric vehicle announcement 88.0 0.6185970306396484\n",
            "Rat infestation allegations 98.5 0.5107200145721436\n",
            "Shipping disruptions. 92.2 0.6704339981079102\n",
            "Sexual harassment probe 99.9 0.47217869758605957\n",
            "Forced labor lawsuit 99.8 0.43048977851867676\n",
            "BBC scandal inquiry 90.2 0.7980868816375732\n",
            "Classified documents leak 88.4 0.646303653717041\n",
            "Decarbonization investment opportunities 46.5 0.7274551391601562\n",
            "Labor negotiations ongoing 96.3 0.635066032409668\n",
            "Wireless charging development 99.2 0.9726474285125732\n",
            "Supply chain management 98.9 0.7412712574005127\n",
            "Sustainability initiative launched 55.0 0.59820556640625\n",
            "Labor policy change 37.4 0.8832592964172363\n",
            "Aviation deal 36.7 0.9147117137908936\n",
            "No incident 38.6 0.5182991027832031\n",
            "Assistance request 76.7 0.5175957679748535\n",
            "Chip shortage incident 90.9 0.6345584392547607\n",
            "A.I. security concerns 84.0 0.709373950958252\n",
            "Carbon removal initiative 99.8 0.7146902084350586\n",
            "Climate change impact 96.3 0.3681216239929199\n",
            "Antitrust concerns 93.0 0.47647881507873535\n",
            "Corporate collaboration announcement 44.9 0.39669036865234375\n",
            "Binance settlement scandal 85.3 0.9452059268951416\n",
            "Brexit impact concerns 72.8 0.4403393268585205\n",
            "Bhopal Gas Tragedy 100.0 0.7612707614898682\n",
            "Electric car production 48.9 0.3945956230163574\n",
            "NHL mask controversy 79.1 0.4781060218811035\n",
            "Media Bias Accusations 97.2 0.6536478996276855\n",
            "Royalty model changes 99.4 0.9029860496520996\n",
            "Wheelchair mishandling incident 77.1 0.5620393753051758\n",
            "Coastal erosion 99.9 0.8778176307678223\n",
            "Gender bias apology 99.6 0.7008326053619385\n",
            "Transgender inclusion controversy 77.7 0.38613080978393555\n",
            "Stock sale incident 94.6 0.5264413356781006\n",
            "Manufacturing incentives scheme 92.6 0.4000890254974365\n",
            "Profit increase 83.5 0.45238685607910156\n",
            "Fraud detection partnership 98.9 0.5746674537658691\n",
            "Rank hypocrisy accusations 34.6 0.6373622417449951\n",
            "Texting improvements announced 72.1 0.49886584281921387\n",
            "Return-to-office mandate 81.5 0.9657104015350342\n",
            "Antisemitic conspiracy theory 99.6 0.5430970191955566\n",
            "Starbucks employee walkout 99.6 0.623650074005127\n",
            "Hybrid transition announcement 83.9 0.7027959823608398\n",
            "Financial performance report 71.5 0.905681848526001\n",
            "Greenwashing accusation 100.0 0.7523496150970459\n",
            "Scam alert 62.8 0.4187166690826416\n",
            "Fossil-free steel 74.6 0.45388221740722656\n",
            "Average time: 0.7193353700637818\n"
          ]
        }
      ],
      "source": [
        "answers=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "answers_confidence=[\"\" for _ in range(len(not_preprocessed_data))]\n",
        "sum_time=0\n",
        "for i in range(len(not_preprocessed_data)):\n",
        "  start_time=time.time()\n",
        "  article =f\"\"\"You are an incident recognition endpoint, for each given text return incident. Your answer cannot be longer than 3 words.\n",
        "\n",
        "  Text:\n",
        "\n",
        "  {not_preprocessed_data[i]}\n",
        "  \"\"\"\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "      {\"role\": \"user\", \"content\": article}\n",
        "    ],\n",
        "    logprobs=True,\n",
        "    top_logprobs=5,\n",
        "    seed=123,\n",
        "    temperature=0\n",
        "  )\n",
        "  end_time=time.time()\n",
        "  answers[i] = completion.choices[0].message.content\n",
        "  power=completion.choices[0].logprobs.content[0].top_logprobs[0].logprob\n",
        "  answers_confidence[i] = np.round(np.exp(power)*100, 1)\n",
        "  sum_time+=end_time-start_time\n",
        "  print(answers[i], answers_confidence[i], end_time-start_time)\n",
        "\n",
        "df_incidents['Incident_3']= answers\n",
        "df_incidents['Confidence_3']= answers_confidence\n",
        "df_incidents['Time_3']= end_time-start_time\n",
        "print(f\"Average time: {sum_time/len(not_preprocessed_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "BgSxrOoON_pJ"
      },
      "outputs": [],
      "source": [
        "# Save results of experiments\n",
        "df_incidents.to_csv(PATH_TO_SAVE_PREPROCESSED+'/gpt_4o_incidents.csv', index=False, sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### For all three experiments incident, model confidence and time was saved"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "objS6y47YDKl",
        "outputId": "2a491a85-3724-44d3-fc9f-01a46488d99d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Article</th>\n",
              "      <th>Incident</th>\n",
              "      <th>Confidence</th>\n",
              "      <th>Time</th>\n",
              "      <th>Incident_2</th>\n",
              "      <th>Confidence_2</th>\n",
              "      <th>Time_2</th>\n",
              "      <th>Incident_3</th>\n",
              "      <th>Confidence_3</th>\n",
              "      <th>Time_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>People work in the Amazon Fulfillment Center i...</td>\n",
              "      <td>Workplace bullying incident</td>\n",
              "      <td>89.3</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Workplace bullying incident</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Workplace bullying incident</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A federal agency is seeking to force Starbucks...</td>\n",
              "      <td>Labor dispute escalation</td>\n",
              "      <td>77.7</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Labor dispute escalation</td>\n",
              "      <td>77.7</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Labor dispute escalation</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>You might have seen a new energy drink on Amaz...</td>\n",
              "      <td>Worker exploitation allegations</td>\n",
              "      <td>80.4</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Worker exploitation allegations</td>\n",
              "      <td>80.2</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Worker exploitation allegations</td>\n",
              "      <td>80.2</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The BBC's director-general has tried to calm t...</td>\n",
              "      <td>Workplace tensions</td>\n",
              "      <td>98.6</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Workplace tensions</td>\n",
              "      <td>98.6</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Workplace tensions</td>\n",
              "      <td>98.6</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazon is running a competition to give its br...</td>\n",
              "      <td>Worker protests Amazon</td>\n",
              "      <td>85.2</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Worker exploitation</td>\n",
              "      <td>87.9</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Worker exploitation</td>\n",
              "      <td>87.9</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>READ MOER: The Tesla killer? Toyota claims its...</td>\n",
              "      <td>Hybrid transition announcement</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Hybrid transition announcement</td>\n",
              "      <td>83.9</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Hybrid transition announcement</td>\n",
              "      <td>83.9</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Exterior view of the Siemens Forum, part of th...</td>\n",
              "      <td>Financial performance report</td>\n",
              "      <td>70.4</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Financial performance report</td>\n",
              "      <td>71.5</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Financial performance report</td>\n",
              "      <td>71.5</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Companies are accused of greenwashing when the...</td>\n",
              "      <td>Greenwashing accusation</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Greenwashing accusation</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Greenwashing accusation</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>It has noted the doubling and quadrupling of t...</td>\n",
              "      <td>Scam alert warning</td>\n",
              "      <td>62.8</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Scam alert</td>\n",
              "      <td>56.1</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Scam alert</td>\n",
              "      <td>62.8</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Sweden-based truck and bus manufacturer Scania...</td>\n",
              "      <td>Fossil-free steel</td>\n",
              "      <td>82.3</td>\n",
              "      <td>0.451547</td>\n",
              "      <td>Fossil-free steel</td>\n",
              "      <td>74.6</td>\n",
              "      <td>0.459337</td>\n",
              "      <td>Fossil-free steel</td>\n",
              "      <td>74.6</td>\n",
              "      <td>0.453882</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Article  \\\n",
              "0   People work in the Amazon Fulfillment Center i...   \n",
              "1   A federal agency is seeking to force Starbucks...   \n",
              "2   You might have seen a new energy drink on Amaz...   \n",
              "3   The BBC's director-general has tried to calm t...   \n",
              "4   Amazon is running a competition to give its br...   \n",
              "..                                                ...   \n",
              "95  READ MOER: The Tesla killer? Toyota claims its...   \n",
              "96  Exterior view of the Siemens Forum, part of th...   \n",
              "97  Companies are accused of greenwashing when the...   \n",
              "98  It has noted the doubling and quadrupling of t...   \n",
              "99  Sweden-based truck and bus manufacturer Scania...   \n",
              "\n",
              "                           Incident  Confidence      Time  \\\n",
              "0       Workplace bullying incident        89.3  0.451547   \n",
              "1          Labor dispute escalation        77.7  0.451547   \n",
              "2   Worker exploitation allegations        80.4  0.451547   \n",
              "3                Workplace tensions        98.6  0.451547   \n",
              "4            Worker protests Amazon        85.2  0.451547   \n",
              "..                              ...         ...       ...   \n",
              "95   Hybrid transition announcement        87.0  0.451547   \n",
              "96     Financial performance report        70.4  0.451547   \n",
              "97          Greenwashing accusation       100.0  0.451547   \n",
              "98               Scam alert warning        62.8  0.451547   \n",
              "99                Fossil-free steel        82.3  0.451547   \n",
              "\n",
              "                         Incident_2  Confidence_2    Time_2  \\\n",
              "0       Workplace bullying incident          81.0  0.459337   \n",
              "1          Labor dispute escalation          77.7  0.459337   \n",
              "2   Worker exploitation allegations          80.2  0.459337   \n",
              "3                Workplace tensions          98.6  0.459337   \n",
              "4               Worker exploitation          87.9  0.459337   \n",
              "..                              ...           ...       ...   \n",
              "95   Hybrid transition announcement          83.9  0.459337   \n",
              "96     Financial performance report          71.5  0.459337   \n",
              "97          Greenwashing accusation         100.0  0.459337   \n",
              "98                       Scam alert          56.1  0.459337   \n",
              "99                Fossil-free steel          74.6  0.459337   \n",
              "\n",
              "                         Incident_3  Confidence_3    Time_3  \n",
              "0       Workplace bullying incident          81.0  0.453882  \n",
              "1          Labor dispute escalation          73.0  0.453882  \n",
              "2   Worker exploitation allegations          80.2  0.453882  \n",
              "3                Workplace tensions          98.6  0.453882  \n",
              "4               Worker exploitation          87.9  0.453882  \n",
              "..                              ...           ...       ...  \n",
              "95   Hybrid transition announcement          83.9  0.453882  \n",
              "96     Financial performance report          71.5  0.453882  \n",
              "97          Greenwashing accusation         100.0  0.453882  \n",
              "98                       Scam alert          62.8  0.453882  \n",
              "99                Fossil-free steel          74.6  0.453882  \n",
              "\n",
              "[100 rows x 10 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_incidents "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bgsAjgbZ1Cf",
        "outputId": "426355c9-aef4-46cc-8959-37bdff9513e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(93)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(df_incidents['Incident']==df_incidents['Incident_2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_qE4tOib1bJ",
        "outputId": "39f15e93-6eff-4ff8-ab98-7edb619e2ac7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(93)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(df_incidents['Incident']==df_incidents['Incident_3'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJlqY6byb3-z",
        "outputId": "206cc32e-d4ec-462e-e9ee-3a692a79a2fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.int64(92)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sum(df_incidents['Incident_2']==df_incidents['Incident_3'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp-ivzjEb5f4",
        "outputId": "80298034-30d9-407d-839e-3818aaaf0cf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80.015\n",
            "79.893\n",
            "79.766\n"
          ]
        }
      ],
      "source": [
        "#mean confidence\n",
        "print(np.mean(df_incidents['Confidence']))\n",
        "print(np.mean(df_incidents['Confidence_2']))\n",
        "print(np.mean(df_incidents['Confidence_3']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyUuJbrfcHiy",
        "outputId": "b5d6abbe-fa5d-4cb4-ee69-19db7829a04a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.45154738426208496\n",
            "0.4593372344970703\n",
            "0.45388221740722656\n"
          ]
        }
      ],
      "source": [
        "#mean time\n",
        "print(np.mean(df_incidents['Time']))\n",
        "print(np.mean(df_incidents['Time_2']))\n",
        "print(np.mean(df_incidents['Time_3']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ut1i-56cLhe",
        "outputId": "e70571a0-a35b-4ca6-959e-2b36e6a6cb50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First answer: Worker protests Amazon; second answer: Worker exploitation; confidence 1: 85.2, confidence 2: 87.9\n",
            "First answer: Advertising boycott; second answer: Advertising boycott X; confidence 1: 62.6, confidence 2: 66.5\n",
            "First answer: Banking climate exit; second answer: Banking sector exit; confidence 1: 56.2, confidence 2: 56.2\n",
            "First answer: Parking fee increases; second answer: Parking fee increase; confidence 1: 99.8, confidence 2: 99.9\n",
            "First answer: Manufacturing shift; second answer: Industry transformation; confidence 1: 26.1, confidence 2: 22.7\n",
            "First answer: Assistance request; second answer: Assisted conversation request; confidence 1: 76.7, confidence 2: 74.9\n",
            "First answer: Scam alert warning; second answer: Scam alert; confidence 1: 62.8, confidence 2: 56.1\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(not_preprocessed_data)):\n",
        "  if df_incidents['Incident'][i]!=df_incidents['Incident_2'][i]:\n",
        "    print(f\"First answer: {df_incidents['Incident'][i]}; second answer: {df_incidents['Incident_2'][i]}; confidence 1: {df_incidents['Confidence'][i]}, confidence 2: {df_incidents['Confidence_2'][i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t_Mr17DckEM",
        "outputId": "21acde54-a794-4a97-9e04-5f7beda1850f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First answer: Banking sector exit; second answer: Banking climate exit; confidence 1: 56.2, confidence 2: 56.2\n",
            "First answer: Parking fee increase; second answer: Parking fee increases; confidence 1: 99.9, confidence 2: 99.9\n",
            "First answer: Industry transformation; second answer: Manufacturing shift; confidence 1: 22.7, confidence 2: 26.1\n",
            "First answer: Classified document leak; second answer: Classified documents leak; confidence 1: 91.6, confidence 2: 88.4\n",
            "First answer: Record jet deal; second answer: Aviation deal; confidence 1: 29.6, confidence 2: 36.7\n",
            "First answer: Assisted conversation request; second answer: Assistance request; confidence 1: 74.9, confidence 2: 76.7\n",
            "First answer: Binance settlement issues; second answer: Binance settlement scandal; confidence 1: 85.0, confidence 2: 85.3\n",
            "First answer: Fraud prevention partnership; second answer: Fraud detection partnership; confidence 1: 98.9, confidence 2: 98.9\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(not_preprocessed_data)):\n",
        "  if df_incidents['Incident_2'][i]!=df_incidents['Incident_3'][i]:\n",
        "    print(f\"First answer: {df_incidents['Incident_2'][i]}; second answer: {df_incidents['Incident_3'][i]}; confidence 1: {df_incidents['Confidence_2'][i]}, confidence 2: {df_incidents['Confidence_3'][i]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQOgBdvocxG-",
        "outputId": "a87367ce-cc3e-42e3-9144-6d909c3de54a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First answer: Worker protests Amazon; second answer: Worker exploitation; confidence 1: 85.2, confidence 2: 87.9\n",
            "First answer: Advertising boycott; second answer: Advertising boycott X; confidence 1: 62.6, confidence 2: 66.5\n",
            "First answer: Classified document leak; second answer: Classified documents leak; confidence 1: 91.6, confidence 2: 88.4\n",
            "First answer: Record jet deal; second answer: Aviation deal; confidence 1: 29.6, confidence 2: 36.7\n",
            "First answer: Binance settlement issues; second answer: Binance settlement scandal; confidence 1: 85.0, confidence 2: 85.3\n",
            "First answer: Fraud prevention partnership; second answer: Fraud detection partnership; confidence 1: 98.9, confidence 2: 98.9\n",
            "First answer: Scam alert warning; second answer: Scam alert; confidence 1: 62.8, confidence 2: 62.8\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(not_preprocessed_data)):\n",
        "  if df_incidents['Incident'][i]!=df_incidents['Incident_3'][i]:\n",
        "    print(f\"First answer: {df_incidents['Incident'][i]}; second answer: {df_incidents['Incident_3'][i]}; confidence 1: {df_incidents['Confidence'][i]}, confidence 2: {df_incidents['Confidence_3'][i]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mjNMyUcwPfZM",
        "zqqW9kn2PSBP",
        "5Gkb7BikFaLt",
        "uGyEC2lt2Rk6"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_actaware",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
